{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectif du notebook :\n",
    "\n",
    "Créer des fonctions qui oeuvreront au même moment que la NER pour protéger des instances sensibles qui ne sont pas des entités nommées, comme !\n",
    "- Des numéros de sécurité sociale\n",
    "- Des sites internet\n",
    "- Des adresses mail\n",
    "- Des plaques d'immatriculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import regex as re\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création de la liste de groupes d'entités :\n",
    "\n",
    "entity_groups = [\"SS\", \"email\", \"plate\", \"phone\", \"date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regex pour les plaques :\n",
    "\n",
    "reg_plate = r\"[A-Z]+[A-Z0-9\\- ]{6,8}\"\n",
    "\n",
    "# Regex pour les numéros\n",
    "\n",
    "reg_num = r\"[0-9+/.\\- ]{6,}\"\n",
    "\n",
    "# Regex pour un email :\n",
    "\n",
    "reg_email = r\"[a-zA-Z0-9.\\-\\_]+@[a-zA-Z0-9.\\-\\_]+\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction qui ajoute les entités non nommées à la liste de NER\n",
    "\n",
    "def add_entities (text:str,\n",
    "                  l : list = None):\n",
    "    if not l:\n",
    "        l = []\n",
    "    plates = re.findall(reg_plate, text)\n",
    "    plates = list(dict.fromkeys(plates))\n",
    "    numbers = re.findall(reg_num, text)\n",
    "    numbers = list(dict.fromkeys(numbers))\n",
    "    emails = re.findall(reg_email, text)\n",
    "    emails = list(dict.fromkeys(emails))\n",
    "    entity_groups = {\"Number\":numbers,\"email\":emails,\"plate\":plates}\n",
    "    \n",
    "    for entity_type in entity_groups.keys():\n",
    "        for item in entity_groups[entity_type]:\n",
    "            if isinstance(item, tuple) and tuple[0] != '':\n",
    "                dic = {}\n",
    "                dic[\"entity_group\"] = entity_type\n",
    "                dic[\"word\"] = item[0]\n",
    "                l.append(dic)\n",
    "            elif isinstance(item, str):\n",
    "                dic = {}\n",
    "                dic[\"entity_group\"] = entity_type\n",
    "                dic[\"word\"] = item\n",
    "                l.append(dic)\n",
    "    return(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/pdf_pseudo_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Fonctions pour la reconnaissance d'entités nommées\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Jean-Baptiste/camembert-ner\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"Jean-Baptiste/camembert-ner\")\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")\n",
    "\n",
    "def identify_ners(text:str) -> list :\n",
    "    ner = nlp(text)\n",
    "    ner = add_entities(text, ner)\n",
    "    return(ner)\n",
    "    \n",
    "# Fonctions pour la pseudonymisation\n",
    "\n",
    "def pseudo(name:str):\n",
    "    return('X'*len(name))\n",
    "\n",
    "def pseudo_all(text : str , file_ners: list):\n",
    "    \"\"\"\n",
    "    Pseudonymizes all NERs within the file.\"\"\"\n",
    "    for i, ner in enumerate(file_ners):\n",
    "        if ner[\"entity_group\"]:\n",
    "            name = ner[\"word\"]\n",
    "            if len(name) > 1:\n",
    "                pseudo_name = pseudo(name)\n",
    "                text = text.replace(name, pseudo_name)\n",
    "    return(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"j'habite au 2 route XXXXXXXX à XXXXXX\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "\n",
    "text = \"j'habite au 2 route tru truc à machin\"\n",
    "\n",
    "ners = identify_ners(text)\n",
    "\n",
    "text_new = pseudo_all(text, ners)\n",
    "\n",
    "text_new"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si utilisé sur onyxia :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Create filesystem object\\nS3_ENDPOINT_URL = \"https://\" + os.environ[\"AWS_S3_ENDPOINT\"]\\nfs = s3fs.S3FileSystem(client_kwargs={\\'endpoint_url\\': S3_ENDPOINT_URL})\\nBUCKET = \"projet-transformers\"\\nFILE_KEY_S3 = \"01092023 - Tests Anonymisation - Outil DINUM 2.csv\"\\nFILE_PATH_S3 = BUCKET + \"/\" + FILE_KEY_S3\\n\\nwith fs.open(FILE_PATH_S3, mode=\"rb\") as file_in:\\n    df_dila = pd.read_csv(file_in, \\n            sep=\";\",\\n            encoding=\\'utf-8\\',\\n            usecols = [\"N°\",\"Message d\\'origine\"],\\n            index_col=0\\n            )'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Create filesystem object\n",
    "S3_ENDPOINT_URL = \"https://\" + os.environ[\"AWS_S3_ENDPOINT\"]\n",
    "fs = s3fs.S3FileSystem(client_kwargs={'endpoint_url': S3_ENDPOINT_URL})\n",
    "BUCKET = \"projet-transformers\"\n",
    "FILE_KEY_S3 = \"Nom fichier.csv\"\n",
    "FILE_PATH_S3 = BUCKET + \"/\" + FILE_KEY_S3\n",
    "\n",
    "with fs.open(FILE_PATH_S3, mode=\"rb\") as file_in:\n",
    "    df_dila = pd.read_csv(file_in, \n",
    "            sep=\";\",\n",
    "            encoding='utf-8',\n",
    "            usecols = [\"N°\",\"Message d'origine\"],\n",
    "            index_col=0\n",
    "            )\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sinon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_in = \"../data/test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message d'origine</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N°</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Je suis madame Truc et j'ai une question sur …</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Message d'origine\n",
       "N°                                                \n",
       "1   Je suis madame Truc et j'ai une question sur …"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dila = pd.read_csv(file_in, \n",
    "            sep=\";\",\n",
    "            encoding='utf-8',\n",
    "            usecols = [\"N°\",\"Message d'origine\"],\n",
    "            index_col=0\n",
    "            )\n",
    "\n",
    "df_dila.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonctions pour process tout le texte\n",
    "\n",
    "def process_text(sentence :str):\n",
    "    ners = identify_ners(sentence)\n",
    "    new_sentence = pseudo_all(sentence, ners)\n",
    "    return(new_sentence)\n",
    "    \n",
    "\n",
    "df_dila[\"Message d'origine\"] = df_dila[\"Message d'origine\"].apply(process_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"BUCKET_OUT = \"projet-transformers\"\n",
    "FILE_KEY_OUT_S3 = \"test_dila_output.csv\"\n",
    "FILE_PATH_OUT_S3 = BUCKET_OUT + \"/\" + FILE_KEY_OUT_S3\n",
    "\n",
    "with fs.open(FILE_PATH_OUT_S3, 'w') as file_out:\n",
    "    df_dila.to_csv(file_out,\n",
    "    #encoding=\"utf-8\",\n",
    "    #sep=\";\"\n",
    "    )\"\"\"\n",
    "\n",
    "\n",
    "# Sinon\n",
    "\n",
    "file_out = \"../data/output.csv\"\n",
    "df_dila.to_csv(file_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message d'origine</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N°</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Je suis madame XXXX et j'ai une question sur …</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Message d'origine\n",
       "N°                                                \n",
       "1   Je suis madame XXXX et j'ai une question sur …"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dila"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pseudo_pdf_tool",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
